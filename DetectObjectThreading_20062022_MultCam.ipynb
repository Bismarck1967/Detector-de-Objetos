{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13b278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(input_image, label, left, top):\n",
    "    \"\"\"Draw text onto image at location.\"\"\"\n",
    "    \n",
    "    # Get text size.\n",
    "    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    cv2.putText(input_image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, BLACK, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def pre_process(input_image, net):\n",
    "    # Create a 4D blob from a frame.\n",
    "    arrayOutput = []\n",
    "    for cams in input_image:\n",
    "        blob = cv2.dnn.blobFromImage(cams, 1/255.0, (INPUT_WIDTH, INPUT_HEIGHT), [0,0,0], 1, crop=False)\n",
    "        \n",
    "        # Sets the input to the network.\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Runs the forward pass to get output of the output layers.\n",
    "        output_layers = net.getUnconnectedOutLayersNames()\n",
    "        outputs = net.forward(output_layers)\n",
    "        \n",
    "        arrayOutput.append(outputs)\n",
    "        # print(outputs[0].shape)\n",
    "        \n",
    "    return (arrayOutput)\n",
    "\n",
    "def post_process(input_image, outputs, CamUso):\n",
    "    # Lists to hold respective values while unwrapping.\n",
    "    global row, image_height\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    cont = 0\n",
    "    for cams in outputs:\n",
    "        # Rows.\n",
    "        rows = cams[0].shape[1]\n",
    "        image_height, image_width = input_image[cont].shape[:2]\n",
    "\n",
    "        # Resizing factor.\n",
    "        x_factor = image_width / INPUT_WIDTH\n",
    "        y_factor =  image_height / INPUT_HEIGHT\n",
    "        \n",
    "        # Iterate through 25200 detections.\n",
    "        for r in range(rows):\n",
    "            row = cams[0][0][r]\n",
    "            confidence = row[4]\n",
    "            \n",
    "            #confidence = max(confidence)\n",
    "            # Discard bad detections and continue.\n",
    "            if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                classes_scores = row[5:]\n",
    "                \n",
    "                # Get the index of max class score.\n",
    "                class_id = np.argmax(classes_scores)\n",
    "\n",
    "                #  Continue if the class score is above threshold.\n",
    "                if (classes_scores[class_id] > SCORE_THRESHOLD):\n",
    "                    confidences.append(confidence)\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "                    cx, cy, w, h = row[0], row[1], row[2], row[3]\n",
    "\n",
    "                    left = int((cx - w/2) * x_factor)\n",
    "                    top = int((cy - h/2) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "                    boxes.append(box)\n",
    "\n",
    "        # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "        # lower confidences.\n",
    "        cont += 1\n",
    "\n",
    "    Linha = 10\n",
    "    ArrayProd = []\n",
    "    \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    for i in indices:\n",
    "        if classes[class_ids[i]] not in ArrayProd: \n",
    "            box = boxes[i]\n",
    "            left = box[0]\n",
    "            top = box[1]\n",
    "            width = box[2]\n",
    "            height = box[3]\n",
    "\n",
    "            label = \"{}:\".format(classes[class_ids[i]])\n",
    "            ArrayProd.append(classes[class_ids[i]])\n",
    "            \n",
    "            #cv2.circle(CamUso, (int(left + width / 2) , int(top + height / 2)), 12, (0, 0, 255), -1)\n",
    "            draw_label(CamUso, label, 20, Linha)\n",
    "            Linha += 25\n",
    "            \n",
    "    return(CamUso)\n",
    "\n",
    "\n",
    "def build_model(is_cuda):\n",
    "#    os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "    \n",
    "    modelWeights = \"/home/pantha/Autonomoous/Pesos/last5s_640_4Prod_ROI.onnx\"\n",
    "    net = cv2.dnn.readNet(modelWeights)\n",
    "\n",
    "    if is_cuda:\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        print(\"[INFO] setting preferable backend and target to CUDA...\")\n",
    "    else:\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        print(\"[INFO] setting preferable backend and target to CPU...\")\n",
    "        \n",
    "    return (net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee2f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] setting preferable backend and target to CUDA...\n",
      "[INFO] sampling THREADED frames from webcam...\n",
      "[INFO] elasped time: 37.39\n",
      "[INFO] approx. FPS: 2.92\n",
      "[INFO] Stop Cameras\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from imutils.video import WebcamVideoStream\n",
    "from imutils.video import FPS\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Constants.\n",
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "SCORE_THRESHOLD = 0.60\n",
    "NMS_THRESHOLD = 0.55\n",
    "CONFIDENCE_THRESHOLD = 0.55\n",
    "\n",
    "# Text parameters.\n",
    "FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.75\n",
    "THICKNESS = 1\n",
    "\n",
    "# Colors\n",
    "BLACK  = (0,0,0)\n",
    "BLUE   = (255,178,50)\n",
    "YELLOW = (0,255,255)\n",
    "RED = (0,0,255)\n",
    "BRANCO = (255,255,255)\n",
    "\n",
    "colors = [(255, 255, 0), (0, 255, 0), (0, 255, 255), (255, 0, 0)]\n",
    "\n",
    "is_cuda = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = build_model(is_cuda)\n",
    "\n",
    "# Load class names.\n",
    "classesFile = \"/home/pantha/Autonomoous/Dataset/Prod_Pantha/classes.txt\"\n",
    "classes = None\n",
    "\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "\n",
    "#stream = cv2.VideoCapture(\"rtsp://192.168.0.18:554/user=admin_password=tlJwpbo6_channel=1_stream=0.sdp?real_stream\")\n",
    "EndCam11 = \"rtsp://192.168.0.11:554/user=admin_password=M1IUut80_channel=1_stream=0.sdp?real_stream\"\n",
    "EndCam15 = \"rtsp://192.168.0.15:554/user=admin_password=tlJwpbo6_channel=1_stream=0.sdp?real_stream\"\n",
    "EndCam17 = \"rtsp://192.168.0.17:554/user=admin_password=tlJwpbo6_channel=1_stream=0.sdp?real_stream\"\n",
    "EndCam18 = \"rtsp://192.168.0.18:554/user=admin_password=tlJwpbo6_channel=1_stream=0.sdp?real_stream\"\n",
    "EndCam19 = \"rtsp://192.168.0.19:554/user=admin_password=tlJwpbo6_channel=1_stream=0.sdp?real_stream\"\n",
    "#EndCam19 = \"/home/pantha/Autonomoous/Dataset/Video/Sucrilhos_Nescau_1.mp4\"\n",
    "\n",
    "print(\"[INFO] sampling THREADED frames from webcam...\")\n",
    "vs11 = WebcamVideoStream(src=EndCam11).start()\n",
    "vs15 = WebcamVideoStream(src=EndCam15).start()\n",
    "vs17 = WebcamVideoStream(src=EndCam17).start()\n",
    "vs18 = WebcamVideoStream(src=EndCam18).start()\n",
    "vs19 = WebcamVideoStream(src=EndCam19).start()\n",
    "\n",
    "fps = FPS().start()\n",
    "# loop over some frames...this time using the threaded stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixel\n",
    "    arrayFrameCams = []\n",
    "    arrayReadCams = []\n",
    "    \n",
    "    frame11 = vs11.read()\n",
    "    frame15 = vs15.read()\n",
    "    frame17 = vs17.read()\n",
    "    frame18 = vs18.read()\n",
    "    frame19 = vs19.read()\n",
    "    \n",
    "    ref_frame11 = imutils.resize(frame11, width=400)\n",
    "    ref_frame15 = imutils.resize(frame15, width=400)\n",
    "    ref_frame17 = imutils.resize(frame17, width=400)\n",
    "    ref_frame18 = imutils.resize(frame18, width=400)\n",
    "    ref_frame19 = imutils.resize(frame19, width=400)\n",
    "    \n",
    "    ref_frame11 = cv2.cvtColor(ref_frame11, cv2.COLOR_BGRA2BGR)\n",
    "    ref_frame15 = cv2.cvtColor(ref_frame15, cv2.COLOR_BGRA2BGR)\n",
    "    ref_frame17 = cv2.cvtColor(ref_frame17, cv2.COLOR_BGRA2BGR)\n",
    "    ref_frame18 = cv2.cvtColor(ref_frame18, cv2.COLOR_BGRA2BGR)\n",
    "    ref_frame19 = cv2.cvtColor(ref_frame19, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    arrayFrameCams.append(ref_frame11)\n",
    "    arrayFrameCams.append(ref_frame15)\n",
    "    arrayFrameCams.append(ref_frame17)\n",
    "    arrayFrameCams.append(ref_frame18)\n",
    "    arrayFrameCams.append(ref_frame19)\n",
    "    \n",
    "    arrayReadCams.append(frame11)\n",
    "    arrayReadCams.append(frame15)\n",
    "    arrayReadCams.append(frame17)\n",
    "    arrayReadCams.append(frame18)\n",
    "    arrayReadCams.append(frame19)\n",
    "      \n",
    "    detections = pre_process(arrayFrameCams, net)\n",
    "    img = post_process(arrayReadCams, detections, frame17)\n",
    "    \n",
    "    output = cv2.resize(img, (800, 600))\n",
    "    \n",
    "    cv2.imshow(\"PanthaVentures - Autonomous\", output)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # update the FPS counter\n",
    "    fps.update()\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "# do a bit of cleanup\n",
    "print(\"[INFO] Stop Cameras\")\n",
    "\n",
    "vs11.stop()\n",
    "vs15.stop()\n",
    "vs17.stop()\n",
    "vs18.stop()\n",
    "vs19.stop()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8d74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
